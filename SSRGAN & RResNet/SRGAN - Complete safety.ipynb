{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.init as init\n",
    "from math import log10\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image, ImageFilter\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from tqdm import tqdm           #display loop evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in [\".png\", \".jpg\", \".jpeg\"])\n",
    "\n",
    "def load_img(filepath):\n",
    "    img = Image.open(filepath).convert('RGB')\n",
    "    return img\n",
    "\n",
    "CROP_SIZE = 32\n",
    "\n",
    "class DatasetFromFolder(Dataset):\n",
    "    def __init__(self, image_dir, scale_factor, with_bicubic_upsampling = True):\n",
    "        super(DatasetFromFolder, self).__init__()\n",
    "        self.image_filenames = [join(image_dir, x) for x in listdir(image_dir) if is_image_file(x)]\n",
    "\n",
    "        crop_size = CROP_SIZE - (CROP_SIZE % scale_factor) # Valid crop size\n",
    "        \n",
    "        if with_bicubic_upsampling:\n",
    "            self.input_transform = transforms.Compose([transforms.CenterCrop(crop_size), # cropping the image\n",
    "                                        transforms.Resize(crop_size//scale_factor),  # subsampling the image (half size)\n",
    "                                        transforms.ToTensor()])\n",
    "        else:\n",
    "            self.input_transform = transforms.Compose([transforms.CenterCrop(crop_size), # cropping the image\n",
    "                                        transforms.Resize(crop_size//scale_factor),  # subsampling the image (half size)\n",
    "                                        transforms.ToTensor()])\n",
    "                \n",
    "        self.target_transform = transforms.Compose([transforms.CenterCrop(crop_size), # since it's the target, we keep its original quality\n",
    "                                       transforms.ToTensor()])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input = load_img(self.image_filenames[index])\n",
    "        target = input.copy()\n",
    "        \n",
    "        input = input.filter(ImageFilter.GaussianBlur(1)) \n",
    "        input = self.input_transform(input)\n",
    "        target = self.target_transform(target)\n",
    "\n",
    "        return input, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "\n",
    "###Classes of Generator and Discriminator\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_channels=64, num_blocks=16):\n",
    "        super(Generator, self).__init__()\n",
    "        self.initial = ConvBlock(in_channels, num_channels, kernel_size=9, stride=1, padding=4, use_bn=False, use_act=True)\n",
    "        self.residuals = nn.Sequential(*[ResidualBlock(num_channels) for _ in range(num_blocks)])\n",
    "        self.convblock = ConvBlock(num_channels, num_channels, kernel_size=3, stride=1, padding=1, use_bn=True, use_act=False)\n",
    "        self.upsamples = nn.Sequential(UpSampleBlock(num_channels, 2), UpSampleBlock(num_channels, 2))\n",
    "        self.final = nn.Conv2d(num_channels, in_channels, kernel_size=9, stride=1, padding=4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        initial = self.initial(x)\n",
    "        x = self.residuals(initial)\n",
    "        x = initial + self.convblock(x)\n",
    "        x = self.upsamples(x)\n",
    "        x = self.final(x)\n",
    "        return torch.tanh(x)\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=3, features=[64, 64, 128, 128, 256, 256, 512, 512]):\n",
    "        super(Discriminator, self).__init__()\n",
    "        blocks = []\n",
    "        for idx, feature in enumerate(features):\n",
    "            blocks.append(ConvBlock(in_channels, feature, kernel_size=3, stride=1+idx%2, padding=1, discriminator=True,\n",
    "                                    use_act=True, use_bn=False if idx==0 else True))\n",
    "            in_channels = feature\n",
    "        \n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((6, 6)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(features[-1]*6*6, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1024, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.blocks(x)\n",
    "        x = self.classifier(x)\n",
    "        return x #torch.sigmoid(x)  ##sigmoid in paper! ...\n",
    "\n",
    "\n",
    "\n",
    "####Classes of model's blocks\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, discriminator=False, use_act=True, use_bn=True, **kwargs):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.use_act = use_act\n",
    "        self.use_bn = use_bn\n",
    "        self.cnn = nn.Conv2d(in_channels, out_channels, **kwargs, bias=not use_bn)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.act = nn.LeakyReLU(0.2, inplace=True) if discriminator else nn.PReLU(num_parameters=out_channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = self.bn(x) if self.use_bn else x\n",
    "        x = self.act(x) if self.use_act else x\n",
    "        return x\n",
    "\n",
    "class UpSampleBlock(nn.Module):\n",
    "    def __init__(self, in_channels, scale_factor):\n",
    "        super(UpSampleBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, in_channels*scale_factor**2, kernel_size=3, stride=1, padding=1)\n",
    "        self.ps = nn.PixelShuffle(scale_factor)\n",
    "        self.act = nn.PReLU(num_parameters=in_channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.ps(x)\n",
    "        return self.act(x)\n",
    "    \n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.block1 = ConvBlock(in_channels, in_channels, kernel_size=3, stride=1, padding=1, use_act=True, use_bn=True)\n",
    "        self.block2 = ConvBlock(in_channels, in_channels, kernel_size=3, stride=1, padding=1, use_act=False, use_bn=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.block1(x)\n",
    "        x2 = self.block2(x1)\n",
    "        return x1 + x2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG-Loss\n",
    "from turtle import forward\n",
    "from torchvision.models import vgg19        #VGG19 to match the paper\n",
    "cuda = True\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and cuda) else \"cpu\")\n",
    "\n",
    "class VGGLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGGLoss, self).__init__()\n",
    "        self.vgg = vgg19(weights='DEFAULT').features[:36].eval().to(device)   #36 to match phi5,4 as in the original paper \n",
    "        self.loss = nn.MSELoss()\n",
    "\n",
    "        for param in self.vgg.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        vgg_input_features = self.vgg(input)\n",
    "        vgg_target_features = self.vgg(target)\n",
    "        return self.loss(vgg_input_features, vgg_target_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [01:49<00:00,  1.73s/it]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average PSNR: 21.192325027306953 dB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [01:43<00:00,  1.65s/it]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average PSNR: 24.29467137150114 dB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [01:37<00:00,  1.55s/it]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average PSNR: 23.139043161349484 dB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [01:26<00:00,  1.37s/it]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average PSNR: 23.17599808513599 dB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [01:34<00:00,  1.50s/it]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average PSNR: 20.86695291307029 dB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [01:25<00:00,  1.36s/it]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average PSNR: 23.53980119071621 dB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [01:34<00:00,  1.50s/it]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average PSNR: 23.81282126493524 dB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [01:21<00:00,  1.29s/it]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average PSNR: 21.70059560689062 dB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [01:16<00:00,  1.21s/it]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average PSNR: 23.565672676147912 dB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [01:30<00:00,  1.43s/it]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average PSNR: 21.865001353147797 dB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [01:42<00:00,  1.63s/it]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average PSNR: 24.979677315668404 dB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [01:19<00:00,  1.26s/it]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average PSNR: 24.95749785022448 dB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [01:19<00:00,  1.26s/it]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average PSNR: 23.183417542697068 dB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [01:32<00:00,  1.47s/it]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average PSNR: 23.596424163593085 dB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [01:23<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average PSNR: 21.942243409689805 dB.\n"
     ]
    }
   ],
   "source": [
    "#Main\n",
    "\n",
    "# Parameters\n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = 0 # on Windows, set this variable to 0\n",
    "LEARNING_RATE = 1e-4\n",
    "scale_factor = 4\n",
    "nb_epochs = 15\n",
    "cuda = True\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and cuda) else \"cpu\")\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "\n",
    "\n",
    "trainset = DatasetFromFolder(\"data/train\", scale_factor=scale_factor)\n",
    "testset = DatasetFromFolder(\"data/test\", scale_factor=scale_factor)\n",
    "\n",
    "trainloader = DataLoader(dataset=trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "testloader = DataLoader(dataset=testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "generator = Generator(in_channels=3).to(device)                 #Working on R,G,B channels\n",
    "discriminator = Discriminator(in_channels=3).to(device)         #Working on R,G,B channels\n",
    "\n",
    "optimizer_generator = optim.Adam(generator.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.999))\n",
    "optimizer_discriminator = optim.Adam(discriminator.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.999))\n",
    "\n",
    "mse = nn.MSELoss()\n",
    "bce = nn.BCEWithLogitsLoss()\n",
    "vgg_loss = VGGLoss()\n",
    "\n",
    "\n",
    "hist_loss_train = []\n",
    "hist_loss_test = []\n",
    "hist_psnr_train = []\n",
    "hist_psnr_test = []\n",
    "for epoch in range(nb_epochs):\n",
    "    # Train\n",
    "    avg_psnr = 0\n",
    "    epoch_loss = 0\n",
    "    for idx, (low_res, high_res) in enumerate(tqdm(trainloader)):\n",
    "        high_res = high_res.to(device)\n",
    "        low_res = low_res.to(device)\n",
    "\n",
    "        ### Train Discriminator: max log(D(x)) + log(1 - D(G(z))) (bce-logit loss)\n",
    "        fake_image_generator = generator(low_res)\n",
    "        output_real_discriminator = discriminator(high_res)\n",
    "        output_fake_discriminator = discriminator(fake_image_generator.detach())\n",
    "\n",
    "        discriminator_loss_real = bce(output_real_discriminator, torch.ones_like(output_real_discriminator) - 0.1*torch.rand_like(output_real_discriminator))\n",
    "        discriminator_loss_fake = bce(output_fake_discriminator, torch.zeros_like(output_fake_discriminator))\n",
    "        discriminator_loss = discriminator_loss_real + discriminator_loss_fake\n",
    "\n",
    "        optimizer_discriminator.zero_grad()\n",
    "        discriminator_loss.backward()\n",
    "        optimizer_discriminator.step()\n",
    "\n",
    "\n",
    "        ### Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n",
    "        output_fake_discriminator = discriminator(fake_image_generator)\n",
    "\n",
    "        adversarial_loss = 1e-3 * bce(output_fake_discriminator, torch.ones_like(output_fake_discriminator))     #in paper also explor l2_loss = mse(fake_image_generator, high_res)\n",
    "        loss_for_vgg = 0.006 * vgg_loss(fake_image_generator, high_res)\n",
    "        generator_loss = adversarial_loss + loss_for_vgg\n",
    "\n",
    "        optimizer_generator.zero_grad()\n",
    "        generator_loss.backward()\n",
    "        optimizer_generator.step()\n",
    "\n",
    "        ##### loss & psnr update\n",
    "        epoch_loss += generator_loss.item()\n",
    "        avg_psnr += 10 * log10(1 / generator_loss.item())\n",
    "\n",
    "    ### loss & psnr train and test\n",
    "    hist_loss_train.append(epoch_loss / len(trainloader))\n",
    "    hist_psnr_train.append(avg_psnr / len(trainloader))\n",
    "\n",
    "    avg_psnr = 0\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in testloader:\n",
    "            input, target = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "            fake_image_generator = generator(input)\n",
    "            output_real_discriminator = discriminator(target)\n",
    "            output_fake_discriminator = discriminator(fake_image_generator.detach())\n",
    "\n",
    "            discriminator_loss_real = bce(output_real_discriminator, torch.ones_like(output_real_discriminator) - 0.1*torch.rand_like(output_real_discriminator))\n",
    "            discriminator_loss_fake = bce(output_fake_discriminator, torch.zeros_like(output_fake_discriminator))\n",
    "            discriminator_loss = discriminator_loss_real + discriminator_loss_fake\n",
    "\n",
    "            output_fake_discriminator = discriminator(fake_image_generator)\n",
    "\n",
    "            adversarial_loss = 1e-3 * bce(output_fake_discriminator, torch.ones_like(output_fake_discriminator))     #in paper also explor l2_loss = mse(fake_image_generator, target)\n",
    "            loss_for_vgg = 0.006 * vgg_loss(fake_image_generator, target)\n",
    "            generator_loss = adversarial_loss + loss_for_vgg\n",
    "\n",
    "            epoch_loss += generator_loss.item()\n",
    "            avg_psnr += 10 * log10(1 / generator_loss.item())\n",
    "\n",
    "    print(f\"Average PSNR: {avg_psnr / len(testloader)} dB.\")\n",
    "    hist_loss_test.append(epoch_loss / len(testloader))\n",
    "    hist_psnr_test.append(avg_psnr / len(testloader))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "##DO NOT RUN CRASH\n",
    "_, ax = plt.subplots(1,2)\n",
    "ax[0].plot(hist_loss_train, label='train loss', c='b')\n",
    "ax[0].plot(hist_loss_test, label='test loss', c='r')\n",
    "ax[0].legend()\n",
    "ax[1].plot(hist_psnr_train, label='train psnr', c='b', linestyle='--')\n",
    "ax[1].plot(hist_psnr_test, label='test psnr', c='r', linestyle='--')\n",
    "ax[1].legend()\n",
    "_.set_size_inches(12,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe Kernel s’est bloqué lors de l’exécution du code dans la cellule active ou une cellule précédente. Veuillez vérifier le code dans la ou les cellules pour identifier une cause possible de l’échec. Cliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus d’informations. Pour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "k = np.random.randint(0,13)\n",
    "for idx, (test_features, test_labels) in enumerate(testloader):\n",
    "    if idx != k: continue;\n",
    "\n",
    "    crop_size = CROP_SIZE - (CROP_SIZE % scale_factor) # Valid crop size\n",
    "    crop = transforms.CenterCrop(crop_size)\n",
    "\n",
    "    LR_original = crop(test_labels[0]).squeeze()\n",
    "    LR = test_features[0].squeeze()     #Low Resolution (bicubiced) image\n",
    "    GT = test_labels[0].squeeze()      #Ground Truth\n",
    "    HR = (generator(test_features.to(device)).cpu().squeeze()[0].detach().numpy()*255.0).clip(0,255)        #High Resolution SRCNN image\n",
    "\n",
    "    _, ax = plt.subplots(1,4, gridspec_kw={'width_ratios': [1, scale_factor, scale_factor, scale_factor]})\n",
    "    ax[0].imshow(LR_original, cmap=\"gray\")\n",
    "    ax[1].imshow(LR, cmap=\"gray\")\n",
    "    ax[2].imshow(HR, cmap=\"gray\")   \n",
    "    ax[3].imshow(GT, cmap=\"gray\")\n",
    "    ax[0].title.set_text('LR image')\n",
    "    ax[1].title.set_text('LR-bicubiced image')\n",
    "    ax[2].title.set_text('HR image (SRCNN)')\n",
    "    ax[3].title.set_text('HR image (ground truth)')\n",
    "\n",
    "    _.set_size_inches(13,13)\n",
    "    for i in range(4): ax[i].set_axis_off()\n",
    "    plt.show()\n",
    "    #print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "f94ef0404597c76b8ce351764d1e3ed736c95433ff01216c9a0de8fbb54ec8de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
